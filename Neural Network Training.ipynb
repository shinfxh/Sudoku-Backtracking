{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from math import *;\n",
    "import numpy as np;\n",
    "from scipy import *;\n",
    "import pandas as pd;\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"sudoku.csv\");\n",
    "data=np.array(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle_grids=data[:,0];\n",
    "sol_grids=data[:,1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=[];\n",
    "y_train=[];\n",
    "x_test=[];\n",
    "y_test=[];\n",
    "zeroes=[0]*9;\n",
    "all_nums=np.array([i for i in range(10)]);\n",
    "train_index_start=0;\n",
    "train_index_end=train_index_start+100000;\n",
    "test_index_start=train_index_end;\n",
    "test_index_end=test_index_start+10000;\n",
    "\n",
    "for index in range(train_index_start, train_index_end):\n",
    "    grid=[float(num)/10 for num in data[index][0]];\n",
    "    x_train.append(grid);\n",
    "    #sol_grid=[int(num) for num in data[index][1]];\n",
    "    y_train.append(int(data[index][1][0]));\n",
    "    \n",
    "x_train=np.array(x_train);\n",
    "y_train=np.array(y_train);\n",
    "    \n",
    "for index in range(test_index_start, test_index_end):\n",
    "    grid=[float(num)/10 for num in data[index][0]];\n",
    "    x_test.append(grid);\n",
    "    #sol_grid=[int(num) for num in data[index][1]];\n",
    "    y_test.append(int(data[index][1][0]));\n",
    "x_test=np.array(x_test);\n",
    "y_test=np.array(y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32');\n",
    "x_train=x_train.reshape(x_train.shape[0], 9, 9, 1);\n",
    "#y_train=y_train.reshape(y_train.shape[0], y_train.shape[1], y_train.shape[2], 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential();\n",
    "model.add(Flatten())\n",
    "model.add(Dense(81, activation='relu', input_shape=(9,9,1)))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(81, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2757 - accuracy: 0.1141\n",
      "Epoch 2/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2695 - accuracy: 0.1142\n",
      "Epoch 3/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2637 - accuracy: 0.1141\n",
      "Epoch 4/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2582 - accuracy: 0.1152\n",
      "Epoch 5/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2531 - accuracy: 0.1154\n",
      "Epoch 6/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2483 - accuracy: 0.1163\n",
      "Epoch 7/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2437 - accuracy: 0.1173\n",
      "Epoch 8/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2395 - accuracy: 0.1174\n",
      "Epoch 9/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2355 - accuracy: 0.1182\n",
      "Epoch 10/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2319 - accuracy: 0.1181\n",
      "Epoch 11/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2284 - accuracy: 0.1191\n",
      "Epoch 12/12\n",
      "100000/100000 [==============================] - 0s 2us/step - loss: 2.2253 - accuracy: 0.1190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1bb64e4c7c8>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=x_train.shape[0], epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 #activation='relu',\n",
    "                 #input_shape=input_shape))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', input_shape=input_shape))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.5004 - accuracy: 0.8530 - val_loss: 0.2213 - val_accuracy: 0.9367\n",
      "Test loss: 0.22130264756381512\n",
      "Test accuracy: 0.9366999864578247\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
